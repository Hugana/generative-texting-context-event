# Cyberpunk 2077: Context-Aware Generative Texting

This project creates a bridge between **Cyberpunk 2077's internal game state** (Redscript engine) and **Large Language Models** (LLMs). While standard generative mods allow for generic conversation, this system injects real-time, high-fidelity context—Quest Objectives, Police Heat Levels, and Weather Conditions—into the LLM's system prompt, allowing companions to react dynamically to the player's immediate reality.
(all the images use OpenAI API)


## The Difference: Context Matters

Standard LLM integration often feels disconnected from gameplay. This system fixes that by injecting the player's active Quest and current Objective into the prompt pipeline.

| **Standard Generative AI** | **Context-Aware System** |
| :---: | :---: |
| ![No Context](Images/NoContextMessage.png)<br>Witout quest context the character seems unaware of the world._ | ![With Context](Images/WithContextMessage.png)<br>With the quest "Riders on the Storm" being tracked the character knows the current state of the world._ |


## Features & Event Systems

### 1. Dynamic "Heat" Reactivity
The system hooks into the `PreventionSystem` to detect changes in police pursuit levels. It calculates a probability curve based on the threat level (1 Star = Low probability, 5 Stars = 100% probability) to trigger organic reactions.

| **Low Heat (Level 1)** | **Maximum Heat (Level 5)** |
| :---: | :---: |
| ![Heat Level 1](Images/PoliceEventHeatLvl1.png)<br>_Casual warning about minor trouble._ | ![Heat Level 5](Images/PoliceEventHeatLvl5.png)<br>_Urgent, high-stakes reaction._ |


### 2. Environmental Awareness (Weather Monitor)
Using a custom **Polling Monitor Pattern** (to bypass native API limitations), the system tracks changes in `worldRainIntensity`.
* **Light Rain:** Triggers low-priority warnings.
* **Heavy Rain:** Triggers comments on visibility and driving safety.

![Weather Event](Images/WeatherEventMessage.png)
<br>Companion reacting to a sudden weather shift.<br>


## Under the Hood: Prompt Engineering

To ensure the LLM adheres to the game's narrative, I engineered structured prompt templates that update dynamically based on game state.

### The "Quest Context" Template
This logic resides in `ContextDataSystem.reds`. It maps raw quest titles to narrative summaries to ensure the AI understands the *stakes*, not just the objective.

```text
MISSION: Riders on the Storm. CONTEXT: My leader, Saul, has been kidnapped by the Wraiths.They are holding him at their camp in Sierra Sonora.
We are currently in the middle of a rescue operation.I am terrified of losing him but trying to stay focused.
There is a dust storm approaching which gives us cover but adds urgency.
CURRENT SITUATION: We are currently:Meet with Panam.React to V based on this specific situation.
```

### The "Weather Event" Template
```text
[SYSTEM EVENT: [ENVIRONMENT EVENT: Heavy storm or hazardous rain detected. Low visibility. Warn V to drive carefully.]] V: *System Update* 
```

### The "Police Event" Template
```text
[INSTRUCTION: You are roleplaying. V just gained police heat. Send V a text message reacting to this.DO NOT output the heat level. DO NOT output your mood. DO NOT output your name. Output ONLY the text message body.
Context: "Heat 1 – Mild concern. A light, cautious reaction. You notice the trouble but stay composed.Tone: wary, slightly annoyed, or amused, depending on your personality.
```

## Core Systems
ContextDataSystem (Passive Data Layer):
  - Responsible for extracting raw data (Quest Title, Weather Enum, Heat Int).
  - Formats raw data into human-readable Prompt Snippets.
  - Contains the "Hardcoded Mapper" for Quest Context to ensure 100% narrative consistency on key missions.

ContextEventManager (Active Logic Layer):
  - Weather Monitor: Implements a resource-efficient 5-second polling loop to detect weather changes (adapting to the lack of a public RegisterListener API).
  - Safety Lock (IsPlayerBusy): Checks scene_tier and is_in_dialogue flags. If V is in a cutscene, incoming messages are snoozed  ensuring the mod never interrupts narrative moments.

GenerativeTextingHttpRequests (Network Layer):
  - Handles the async API calls to OpenAI/Stable Horde.
  - Injects the pendingContext payload generated by the Event Manager.

## Credits
- Original Mod: https://www.nexusmods.com/cyberpunk2077/mods/17922 (Used as the base for UI/HTTP handling).
- Extension Author: [Hugo Ferreira] - Implemented Context Systems, Event Listeners, and Narrative Logic.

